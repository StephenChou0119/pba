nohup: ignoring input
WARNING: Logging before flag parsing goes to stderr.
W0716 20:30:33.591191 140126398576384 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0716 20:30:33.820289 140126398576384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:86: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0716 20:30:33.820526 140126398576384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:86: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0716 20:30:33.820655 140126398576384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:87: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0716 20:30:33.823213 140126398576384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/setup.py:76: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0716 20:30:33.823376 140126398576384 setup.py:76] Namespace(bs=512, checkpoint_freq=5, cpu=5.0, epochs=10, explore='cifar10', gpu=1.0, hp_policy='/data/zwy/hack_pba_tensorflow/schedules/hack.txt', hp_policy_epochs=10, local_dir='/data/zwy/hack_pba_tensorflow/results/resnet/', lr=0.1, model_name='resnet', name='resnet_train', no_aug=False, no_cutout=False, num_samples=10, resnet_size=18, restore=None, test_bs=512, use_hp_policy=True, wd=0.0005)
I0716 20:30:33.823531 140126398576384 setup.py:164] epochs: 10, lr: 0.1, wd: 0.0005
2019-07-16 20:30:33,824	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-16_20-30-33_823894_14572/logs.
2019-07-16 20:30:33,941	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:17238 to respond...
2019-07-16 20:30:34,092	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:22397 to respond...
2019-07-16 20:30:34,094	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2019-07-16 20:30:34,165	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-16_20-30-33_823894_14572/logs.
2019-07-16 20:30:34,166	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2019-07-16 20:30:34,167	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2019-07-16 20:30:34,301	INFO tune.py:65 -- Did not find checkpoint file in /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train.
2019-07-16 20:30:34,301	INFO tune.py:233 -- Starting a new experiment.
W0716 20:30:34.646364 140126398576384 deprecation_wrapper.py:119] From /data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

W0716 20:30:34.646880 140126398576384 deprecation_wrapper.py:119] From /data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2019-07-16 20:30:34,785	WARNING util.py:64 -- The `start_trial` operation took 0.19972777366638184 seconds to complete, which may be a performance bottleneck.
2019-07-16 20:30:38,880	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14714, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f911a3b4518>

2019-07-16 20:30:38,882	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:38,885	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:38,909	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14699, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7feea17ef518>

2019-07-16 20:30:38,910	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:38,911	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:38,928	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14723, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7efd165f1588>

2019-07-16 20:30:38,929	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:38,929	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/8 GPUs
Memory usage on this node: 3.2/270.4 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 5.0/40 CPUs, 1.0/8 GPUs
Memory usage on this node: 3.4/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - RayModel_1:	PENDING
 - RayModel_2:	PENDING
 - RayModel_3:	PENDING
 - RayModel_4:	PENDING
 - RayModel_5:	PENDING
 - RayModel_6:	PENDING
 - RayModel_7:	PENDING
 - RayModel_8:	PENDING
 - RayModel_9:	PENDING
RUNNING trials:
 - RayModel_0:	RUNNING

[2m[36m(pid=14714)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14714)[0m W0716 20:30:38.609174 140264436709120 lazy_loader.py:50] 
[2m[36m(pid=14714)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14714)[0m For more information, please see:
[2m[36m(pid=14714)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14714)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14714)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14714)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14714)[0m 
[2m[36m(pid=14699)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14699)[0m W0716 20:30:38.604837 140666063591168 lazy_loader.py:50] 
[2m[36m(pid=14699)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14699)[0m For more information, please see:
[2m[36m(pid=14699)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14699)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14699)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14699)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14699)[0m 
[2m[36m(pid=14733)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14733)[0m W0716 20:30:38.698890 139661514635008 lazy_loader.py:50] 
[2m[36m(pid=14733)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14733)[0m For more information, please see:
[2m[36m(pid=14733)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14733)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14733)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14733)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14733)[0m 
[2m[36m(pid=14734)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14734)[0m W0716 20:30:38.673990 140151234516736 lazy_loader.py:50] 
[2m[36m(pid=14734)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14734)[0m For more information, please see:
[2m[36m(pid=14734)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14734)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14734)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14734)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14734)[0m 
[2m[36m(pid=14696)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14696)[0m W0716 20:30:38.654490 139797585843968 lazy_loader.py:50] 
[2m[36m(pid=14696)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14696)[0m For more information, please see:
[2m[36m(pid=14696)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14696)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14696)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14696)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14696)[0m 
[2m[36m(pid=14723)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14723)[0m W0716 20:30:38.662855 139628978853632 lazy_loader.py:50] 
[2m[36m(pid=14723)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14723)[0m For more information, please see:
[2m[36m(pid=14723)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14723)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14723)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14723)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14723)[0m 
[2m[36m(pid=14721)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14721)[0m W0716 20:30:38.708199 140165662852864 lazy_loader.py:50] 
[2m[36m(pid=14721)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14721)[0m For more information, please see:
[2m[36m(pid=14721)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14721)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14721)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14721)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14721)[0m 
[2m[36m(pid=14727)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14727)[0m W0716 20:30:38.708204 140024657725184 lazy_loader.py:50] 
[2m[36m(pid=14727)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14727)[0m For more information, please see:
[2m[36m(pid=14727)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14727)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14727)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14727)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14727)[0m 
[2m[36m(pid=14734)[0m W0716 20:30:38.919379 140151234516736 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14734)[0m 
[2m[36m(pid=14734)[0m W0716 20:30:38.919717 140151234516736 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14734)[0m 
[2m[36m(pid=14734)[0m W0716 20:30:38.919939 140151234516736 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14734)[0m 
[2m[36m(pid=14734)[0m I0716 20:30:38.920066 140151234516736 train.py:24] calling setup
[2m[36m(pid=14734)[0m I0716 20:30:38.920396 140151234516736 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14696)[0m W0716 20:30:38.920289 139797585843968 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14696)[0m 
[2m[36m(pid=14696)[0m W0716 20:30:38.920629 139797585843968 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14696)[0m 
[2m[36m(pid=14696)[0m W0716 20:30:38.920853 139797585843968 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14696)[0m 
[2m[36m(pid=14696)[0m I0716 20:30:38.920978 139797585843968 train.py:24] calling setup
[2m[36m(pid=14696)[0m I0716 20:30:38.921533 139797585843968 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.02019-07-16 20:30:38,947	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14734, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f76b4afd518>

2019-07-16 20:30:38,948	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:38,949	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:38,965	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14733, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f0493bed588>

2019-07-16 20:30:38,966	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:38,967	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:38,985	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14727, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f5921fe25c0>

2019-07-16 20:30:38,987	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:38,988	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:39,017	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14696, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f246c29e5c0>

2019-07-16 20:30:39,018	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:39,019	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:39,046	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14721, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f7a1f4a2518>

2019-07-16 20:30:39,047	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:39,048	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=14714)[0m W0716 20:30:38.873148 140264436709120 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14714)[0m 
[2m[36m(pid=14714)[0m W0716 20:30:38.873376 140264436709120 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14714)[0m 
[2m[36m(pid=14714)[0m W0716 20:30:38.873479 140264436709120 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14714)[0m 
[2m[36m(pid=14714)[0m I0716 20:30:38.873537 140264436709120 train.py:24] calling setup
[2m[36m(pid=14714)[0m I0716 20:30:38.873763 140264436709120 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14699)[0m W0716 20:30:38.883854 140666063591168 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14699)[0m 
[2m[36m(pid=14699)[0m W0716 20:30:38.884174 140666063591168 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14699)[0m 
[2m[36m(pid=14699)[0m W0716 20:30:38.884365 140666063591168 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14699)[0m 
[2m[36m(pid=14699)[0m I0716 20:30:38.884494 140666063591168 train.py:24] calling setup
[2m[36m(pid=14699)[0m I0716 20:30:38.884797 140666063591168 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14723)[0m W0716 20:30:38.912169 139628978853632 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14723)[0m 
[2m[36m(pid=14723)[0m W0716 20:30:38.912477 139628978853632 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14723)[0m 
[2m[36m(pid=14723)[0m W0716 20:30:38.912719 139628978853632 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14723)[0m 
[2m[36m(pid=14723)[0m I0716 20:30:38.912829 139628978853632 train.py:24] calling setup
[2m[36m(pid=14723)[0m I0716 20:30:38.913342 139628978853632 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14733)[0m W0716 20:30:38.948822 139661514635008 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14733)[0m 
[2m[36m(pid=14733)[0m W0716 20:30:38.949039 139661514635008 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14733)[0m 
[2m[36m(pid=14733)[0m W0716 20:30:38.949149 139661514635008 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14733)[0m 
[2m[36m(pid=14733)[0m I0716 20:30:38.949217 139661514635008 train.py:24] calling setup
[2m[36m(pid=14733)[0m I0716 20:30:38.949554 139661514635008 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14721)[0m W0716 20:30:38.948425 140165662852864 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14721)[0m 
[2m[36m(pid=14721)[0m W0716 20:30:38.948776 140165662852864 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14721)[0m 
[2m[36m(pid=14721)[0m W0716 20:30:38.948975 140165662852864 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14721)[0m 
[2m[36m(pid=14721)[0m I0716 20:30:38.949097 140165662852864 train.py:24] calling setup
[2m[36m(pid=14721)[0m I0716 20:30:38.949667 140165662852864 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14727)[0m W0716 20:30:38.951087 140024657725184 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14727)[0m 
[2m[36m(pid=14727)[0m W0716 20:30:38.951473 140024657725184 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14727)[0m 
[2m[36m(pid=14727)[0m W0716 20:30:38.951697 140024657725184 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14727)[0m 
[2m[36m(pid=14727)[0m I0716 20:30:38.951844 140024657725184 train.py:24] calling setup
[2m[36m(pid=14727)[0m I0716 20:30:38.952468 140024657725184 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16508)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16508)[0m W0716 20:30:41.921045 140463889966848 lazy_loader.py:50] 
[2m[36m(pid=16508)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16508)[0m For more information, please see:
[2m[36m(pid=16508)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16508)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16508)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16508)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16508)[0m 
[2m[36m(pid=16516)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16516)[0m W0716 20:30:41.972622 140072967337728 lazy_loader.py:50] 
[2m[36m(pid=16516)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16516)[0m For more information, please see:
[2m[36m(pid=16516)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16516)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16516)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16516)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16516)[0m 
[2m[36m(pid=16495)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16495)[0m W0716 20:30:42.050299 140106569942784 lazy_loader.py:50] 
[2m[36m(pid=16495)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16495)[0m For more information, please see:
[2m[36m(pid=16495)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md2019-07-16 20:30:42,180	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16508, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fbf8ef9d5c0>

2019-07-16 20:30:42,181	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,183	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:42,218	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16516, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f648a315588>

2019-07-16 20:30:42,219	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,220	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:42,261	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16502, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fa1e80dc588>

2019-07-16 20:30:42,263	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,264	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:42,278	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16480, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f2a090a9588>

2019-07-16 20:30:42,279	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,280	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=16495)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16495)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16495)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16495)[0m 
[2m[36m(pid=16480)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16480)[0m W0716 20:30:42.008729 139822475921152 lazy_loader.py:50] 
[2m[36m(pid=16480)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16480)[0m For more information, please see:
[2m[36m(pid=16480)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16480)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16480)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16480)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16480)[0m 
[2m[36m(pid=16490)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16490)[0m W0716 20:30:42.021170 139866610808576 lazy_loader.py:50] 
[2m[36m(pid=16490)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16490)[0m For more information, please see:
[2m[36m(pid=16490)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16490)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16490)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16490)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16490)[0m 
[2m[36m(pid=16485)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16485)[0m W0716 20:30:42.033154 140423278872320 lazy_loader.py:50] 
[2m[36m(pid=16485)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16485)[0m For more information, please see:
[2m[36m(pid=16485)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16485)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16485)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16485)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16485)[0m 
[2m[36m(pid=16502)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16502)[0m W0716 20:30:42.007683 140336535037696 lazy_loader.py:50] 
[2m[36m(pid=16502)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16502)[0m For more information, please see:
[2m[36m(pid=16502)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16502)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16502)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16502)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16502)[0m 
[2m[36m(pid=16493)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16493)[0m W0716 20:30:42.154592 140446212437760 lazy_loader.py:50] 
[2m[36m(pid=16493)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16493)[0m For more information, please see:
[2m[36m(pid=16493)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16493)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16493)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16493)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16493)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40.0/40 CPUs, 8.0/8 GPUs
Memory usage on this node: 5.7/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'RUNNING': 8, 'PENDING': 2})
PENDING trials:
 - RayModel_8:	PENDING
 - RayModel_9:	PENDING
RUNNING trials:
 - RayModel_0:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-34h2rikp5j/error_2019-07-16_20-30-38.txt
 - RayModel_1:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-34cwdpcpru/error_2019-07-16_20-30-38.txt
 - RayModel_2:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-34mtk1vlr2/error_2019-07-16_20-30-38.txt
 - RayModel_3:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-34i4_c_d0f/error_2019-07-16_20-30-39.txt
 - RayModel_4:	RUNNING, 2 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-35rna3l0wt/error_2019-07-16_20-30-42.txt
 - RayModel_5:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-35xpqfjof8/error_2019-07-16_20-30-39.txt
 - RayModel_6:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-35v02rcans/error_2019-07-16_20-30-38.txt
 - RayModel_7:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-350tzpwwnu/error_2019-07-16_20-30-38.txt

[2m[36m(pid=16516)[0m W0716 20:30:42.211849 140072967337728 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16516)[0m 
[2m[36m(pid=16516)[0m W0716 20:30:42.212050 140072967337728 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16516)[0m 
[2m[36m(pid=16516)[0m W0716 20:30:42.212160 140072967337728 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16516)[0m 
[2m[36m(pid=16516)[0m I0716 20:30:42.212226 140072967337728 train.py:24] calling setup
[2m[36m(pid=16516)[0m I0716 20:30:42.212483 140072967337728 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16508)[0m W0716 20:30:42.173491 140463889966848 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16508)[0m 
[2m[36m(pid=16508)[0m W0716 20:30:42.173780 140463889966848 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16508)[0m 
[2m[36m(pid=16508)[0m W0716 20:30:42.173918 140463889966848 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16508)[0m 
[2m[36m(pid=16508)[0m I0716 20:30:42.174010 140463889966848 train.py:24] calling setup
[2m[36m(pid=16508)[0m I0716 20:30:42.174495 140463889966848 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16480)[0m W0716 20:30:42.258626 139822475921152 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16480)[0m 
[2m[36m(pid=16480)[0m W0716 20:30:42.258874 139822475921152 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16480)[0m 
[2m[36m(pid=16480)[0m W0716 20:30:42.258987 139822475921152 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.2019-07-16 20:30:42,299	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16485, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fb61254c5c0>

2019-07-16 20:30:42,300	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,301	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:42,318	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16490, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f347e616588>

2019-07-16 20:30:42,320	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,320	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:42,337	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16495, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f6c32fa3518>

2019-07-16 20:30:42,339	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,339	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:42,418	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16493, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fbb6b53b550>

2019-07-16 20:30:42,420	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:42,420	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=16480)[0m 
[2m[36m(pid=16480)[0m I0716 20:30:42.259078 139822475921152 train.py:24] calling setup
[2m[36m(pid=16480)[0m I0716 20:30:42.259398 139822475921152 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16490)[0m W0716 20:30:42.259128 139866610808576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16490)[0m 
[2m[36m(pid=16490)[0m W0716 20:30:42.259399 139866610808576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16490)[0m 
[2m[36m(pid=16490)[0m W0716 20:30:42.259593 139866610808576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16490)[0m 
[2m[36m(pid=16490)[0m I0716 20:30:42.259698 139866610808576 train.py:24] calling setup
[2m[36m(pid=16490)[0m I0716 20:30:42.260062 139866610808576 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16485)[0m W0716 20:30:42.277792 140423278872320 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16485)[0m 
[2m[36m(pid=16485)[0m W0716 20:30:42.278027 140423278872320 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16485)[0m 
[2m[36m(pid=16485)[0m W0716 20:30:42.278139 140423278872320 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16485)[0m 
[2m[36m(pid=16485)[0m I0716 20:30:42.278245 140423278872320 train.py:24] calling setup
[2m[36m(pid=16485)[0m I0716 20:30:42.278533 140423278872320 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16502)[0m W0716 20:30:42.255601 140336535037696 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16502)[0m 
[2m[36m(pid=16502)[0m W0716 20:30:42.255853 140336535037696 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16502)[0m 
[2m[36m(pid=16502)[0m W0716 20:30:42.255960 140336535037696 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16502)[0m 
[2m[36m(pid=16502)[0m I0716 20:30:42.256024 140336535037696 train.py:24] calling setup
[2m[36m(pid=16502)[0m I0716 20:30:42.256308 140336535037696 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16495)[0m W0716 20:30:42.316137 140106569942784 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16495)[0m 
[2m[36m(pid=16495)[0m W0716 20:30:42.316364 140106569942784 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16495)[0m 
[2m[36m(pid=16495)[0m W0716 20:30:42.316480 140106569942784 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16495)[0m 
[2m[36m(pid=16495)[0m I0716 20:30:42.316550 140106569942784 train.py:24] calling setup
[2m[36m(pid=16495)[0m I0716 20:30:42.316868 140106569942784 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16493)[0m W0716 20:30:42.410071 140446212437760 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16493)[0m 
[2m[36m(pid=16493)[0m W0716 20:30:42.410613 140446212437760 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16493)[0m 
[2m[36m(pid=16493)[0m W0716 20:30:42.410830 140446212437760 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16493)[0m 
[2m[36m(pid=16493)[0m I0716 20:30:42.410951 140446212437760 train.py:24] calling setup
[2m[36m(pid=16493)[0m I0716 20:30:42.411546 140446212437760 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16499)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16499)[0m W0716 20:30:45.171501 140298589390592 lazy_loader.py:50] 
[2m[36m(pid=16499)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16499)[0m For more information, please see:
[2m[36m(pid=16499)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16499)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16499)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16499)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16499)[0m 
[2m[36m(pid=14707)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14707)[0m W0716 20:30:45.228888 139704354346752 lazy_loader.py:50] 
[2m[36m(pid=14707)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14707)[0m For more information, please see:
[2m[36m(pid=14707)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14707)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14707)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14707)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14707)[0m 
[2m[36m(pid=14722)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14722)[0m W0716 20:30:45.375467 140232893601536 lazy_loader.py:50] 
[2m[36m(pid=14722)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14722)[0m For more information, please see:
[2m[36m(pid=14722)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14722)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14722)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14722)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14722)[0m 
[2m[36m(pid=14711)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14711)[0m W0716 20:30:45.408411 140417896916736 lazy_loader.py:50] 
[2m[36m(pid=14711)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14711)[0m For more information, please see:
[2m[36m(pid=14711)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md2019-07-16 20:30:45,467	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16499, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f98e199e6a0>

2019-07-16 20:30:45,469	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,471	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:45,488	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14707, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f0e886f8588>

2019-07-16 20:30:45,489	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,489	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:45,612	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14700, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f1bb49c7588>

2019-07-16 20:30:45,615	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,616	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:45,640	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14722, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f899c98f518>

2019-07-16 20:30:45,642	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,643	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:45,670	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14711, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fb4b9886588>

2019-07-16 20:30:45,672	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,673	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=14711)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14711)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14711)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14711)[0m 
[2m[36m(pid=14700)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14700)[0m W0716 20:30:45.378300 139760651888384 lazy_loader.py:50] 
[2m[36m(pid=14700)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14700)[0m For more information, please see:
[2m[36m(pid=14700)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14700)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14700)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14700)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14700)[0m 
[2m[36m(pid=14707)[0m W0716 20:30:45.469099 139704354346752 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14707)[0m 
[2m[36m(pid=14707)[0m W0716 20:30:45.469349 139704354346752 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14707)[0m 
[2m[36m(pid=14707)[0m W0716 20:30:45.469491 139704354346752 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14707)[0m 
[2m[36m(pid=14707)[0m I0716 20:30:45.469571 139704354346752 train.py:24] calling setup
[2m[36m(pid=14707)[0m I0716 20:30:45.469788 139704354346752 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16499)[0m W0716 20:30:45.458652 140298589390592 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16499)[0m 
[2m[36m(pid=16499)[0m W0716 20:30:45.459033 140298589390592 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16499)[0m 
[2m[36m(pid=16499)[0m W0716 20:30:45.459245 140298589390592 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16499)[0m 
[2m[36m(pid=16499)[0m I0716 20:30:45.459370 140298589390592 train.py:24] calling setup
[2m[36m(pid=16499)[0m I0716 20:30:45.459931 140298589390592 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14701)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14701)[0m W0716 20:30:45.499984 140006843635456 lazy_loader.py:50] 
[2m[36m(pid=14701)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14701)[0m For more information, please see:
[2m[36m(pid=14701)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14701)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14701)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14701)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14701)[0m 
[2m[36m(pid=16482)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16482)[0m W0716 20:30:45.496866 140576081942272 lazy_loader.py:50] 
[2m[36m(pid=16482)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16482)[0m For more information, please see:
[2m[36m(pid=16482)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16482)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16482)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16482)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16482)[0m 
[2m[36m(pid=14722)[0m W0716 20:30:45.607905 140232893601536 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14722)[0m 
[2m[36m(pid=14722)[0m W0716 20:30:45.608093 140232893601536 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14722)[0m 
[2m[36m(pid=14722)[0m W0716 20:30:45.608193 140232893601536 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14722)[0m 
[2m[36m(pid=14722)[0m I0716 20:30:45.608253 140232893601536 train.py:24] calling setup
[2m[36m(pid=14722)[0m I0716 20:30:45.608482 140232893601536 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14700)[0m W0716 20:30:45.605647 139760651888384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14700)[0m 
[2m[36m(pid=14700)[0m W0716 20:30:45.605848 139760651888384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14700)[0m 
[2m[36m(pid=14700)[0m W0716 20:30:45.605942 139760651888384 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14700)[0m 
[2m[36m(pid=14700)[0m I0716 20:30:45.605999 139760651888384 train.py:24] calling setup
[2m[36m(pid=14700)[0m I0716 20:30:45.606244 139760651888384 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14711)[0m W0716 20:30:45.665395 140417896916736 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14711)[0m 
[2m[36m(pid=14711)[0m W0716 20:30:45.665610 140417896916736 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14711)[0m 
[2m[36m(pid=14711)[0m W0716 20:30:45.665721 140417896916736 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14711)[0m 
[2m[36m(pid=14711)[0m I0716 20:30:45.665789 140417896916736 train.py:24] calling setup
[2m[36m(pid=14711)[0m I0716 20:30:45.666076 140417896916736 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16487)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16487)[0m W0716 20:30:45.657371 139914911241984 lazy_loader.py:50] 
[2m[36m(pid=16487)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16487)[0m For more information, please see:
[2m[36m(pid=16487)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16487)[0m   * https://github.com/tensorflow/addons2019-07-16 20:30:45,768	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16482, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fd97f095588>

2019-07-16 20:30:45,770	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,771	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:45,796	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14701, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f5524ead588>

2019-07-16 20:30:45,798	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,799	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:45,965	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16487, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f3f91694588>

2019-07-16 20:30:45,966	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:45,967	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:48,720	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14718, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f8940e5a588>

2019-07-16 20:30:48,721	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:48,750	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14715, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7feb2aa65588>

2019-07-16 20:30:48,752	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=16487)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16487)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16487)[0m 
[2m[36m(pid=14701)[0m W0716 20:30:45.764798 140006843635456 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14701)[0m 
[2m[36m(pid=14701)[0m W0716 20:30:45.765177 140006843635456 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14701)[0m 
[2m[36m(pid=14701)[0m W0716 20:30:45.765408 140006843635456 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14701)[0m 
[2m[36m(pid=14701)[0m I0716 20:30:45.765533 140006843635456 train.py:24] calling setup
[2m[36m(pid=14701)[0m I0716 20:30:45.766146 140006843635456 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16482)[0m W0716 20:30:45.761893 140576081942272 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16482)[0m 
[2m[36m(pid=16482)[0m W0716 20:30:45.762149 140576081942272 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16482)[0m 
[2m[36m(pid=16482)[0m W0716 20:30:45.762271 140576081942272 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16482)[0m 
[2m[36m(pid=16482)[0m I0716 20:30:45.762339 140576081942272 train.py:24] calling setup
[2m[36m(pid=16482)[0m I0716 20:30:45.762660 140576081942272 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16487)[0m W0716 20:30:45.958529 139914911241984 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16487)[0m 
[2m[36m(pid=16487)[0m W0716 20:30:45.958767 139914911241984 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16487)[0m 
[2m[36m(pid=16487)[0m W0716 20:30:45.958878 139914911241984 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16487)[0m 
[2m[36m(pid=16487)[0m I0716 20:30:45.958946 139914911241984 train.py:24] calling setup
[2m[36m(pid=16487)[0m I0716 20:30:45.959275 139914911241984 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14718)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14718)[0m W0716 20:30:48.461019 140230661338880 lazy_loader.py:50] 
[2m[36m(pid=14718)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14718)[0m For more information, please see:
[2m[36m(pid=14718)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14718)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14718)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14718)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14718)[0m 
[2m[36m(pid=14715)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14715)[0m W0716 20:30:48.517526 140651887875840 lazy_loader.py:50] 
[2m[36m(pid=14715)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14715)[0m For more information, please see:
[2m[36m(pid=14715)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14715)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14715)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14715)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14715)[0m 
[2m[36m(pid=14724)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14724)[0m W0716 20:30:48.505836 140314868713216 lazy_loader.py:50] 
[2m[36m(pid=14724)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14724)[0m For more information, please see:
[2m[36m(pid=14724)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14724)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14724)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14724)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14724)[0m 
[2m[36m(pid=14730)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14730)[0m W0716 20:30:48.687093 139741213026048 lazy_loader.py:50] 
[2m[36m(pid=14730)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14730)[0m For more information, please see:
[2m[36m(pid=14730)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14730)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14730)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14730)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14730)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 35.0/40 CPUs, 7.0/8 GPUs
Memory usage on this node: 5.2/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'RUNNING': 7, 'ERROR': 1, 'PENDING': 2})
ERROR trials:
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-35v02rcans/error_2019-07-16_20-30-48.txt
PENDING trials:
 - RayModel_8:	PENDING
 - RayModel_9:	PENDING
RUNNING trials:
 - RayModel_0:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-34h2rikp5j/error_2019-07-16_20-30-45.txt
 - RayModel_1:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-34cwdpcpru/error_2019-07-16_20-30-45.txt
 - RayModel_2:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-34mtk1vlr2/error_2019-07-16_20-30-45.txt
 - RayModel_3:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-34i4_c_d0f/error_2019-07-16_20-30-45.txt
 - RayModel_4:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-35rna3l0wt/error_2019-07-16_20-30-45.txt
 - RayModel_5:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-35xpqfjof8/error_2019-07-16_20-30-45.txt
 - RayModel_7:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-350tzpwwnu/error_2019-07-16_20-30-45.txt

[2m[36m(pid=14715)[0m W0716 20:30:48.736478 140651887875840 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14715)[0m 
[2m[36m(pid=14715)[0m W0716 20:30:48.736720 140651887875840 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.2019-07-16 20:30:48,780	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14724, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f9cdca57588>

2019-07-16 20:30:48,782	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:48,935	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14730, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f174c19f588>

2019-07-16 20:30:48,937	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:48,964	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14698, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f3a57b64588>

2019-07-16 20:30:48,966	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:48,975	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14729, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f9ed52636a0>

2019-07-16 20:30:48,977	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:49,109	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16504, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f3bf9fbf588>

2019-07-16 20:30:49,111	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=14715)[0m 
[2m[36m(pid=14715)[0m W0716 20:30:48.736826 140651887875840 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14715)[0m 
[2m[36m(pid=14715)[0m I0716 20:30:48.736888 140651887875840 train.py:24] calling setup
[2m[36m(pid=14715)[0m I0716 20:30:48.737146 140651887875840 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14718)[0m W0716 20:30:48.713752 140230661338880 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14718)[0m 
[2m[36m(pid=14718)[0m W0716 20:30:48.713963 140230661338880 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14718)[0m 
[2m[36m(pid=14718)[0m W0716 20:30:48.714064 140230661338880 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14718)[0m 
[2m[36m(pid=14718)[0m I0716 20:30:48.714126 140230661338880 train.py:24] calling setup
[2m[36m(pid=14718)[0m I0716 20:30:48.714373 140230661338880 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14698)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14698)[0m W0716 20:30:48.717711 139892101641984 lazy_loader.py:50] 
[2m[36m(pid=14698)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14698)[0m For more information, please see:
[2m[36m(pid=14698)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14698)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14698)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14698)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14698)[0m 
[2m[36m(pid=14724)[0m W0716 20:30:48.736888 140314868713216 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14724)[0m 
[2m[36m(pid=14724)[0m W0716 20:30:48.737119 140314868713216 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14724)[0m 
[2m[36m(pid=14724)[0m W0716 20:30:48.737233 140314868713216 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14724)[0m 
[2m[36m(pid=14724)[0m I0716 20:30:48.737296 140314868713216 train.py:24] calling setup
[2m[36m(pid=14724)[0m I0716 20:30:48.737559 140314868713216 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14729)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14729)[0m W0716 20:30:48.707381 140323982214912 lazy_loader.py:50] 
[2m[36m(pid=14729)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14729)[0m For more information, please see:
[2m[36m(pid=14729)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14729)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14729)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14729)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14729)[0m 
[2m[36m(pid=16504)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16504)[0m W0716 20:30:48.822779 139899590280960 lazy_loader.py:50] 
[2m[36m(pid=16504)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16504)[0m For more information, please see:
[2m[36m(pid=16504)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16504)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16504)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16504)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16504)[0m 
[2m[36m(pid=14730)[0m W0716 20:30:48.928292 139741213026048 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14730)[0m 
[2m[36m(pid=14730)[0m W0716 20:30:48.928535 139741213026048 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14730)[0m 
[2m[36m(pid=14730)[0m W0716 20:30:48.928636 139741213026048 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14730)[0m 
[2m[36m(pid=14730)[0m I0716 20:30:48.928695 139741213026048 train.py:24] calling setup
[2m[36m(pid=14730)[0m I0716 20:30:48.928933 139741213026048 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14698)[0m W0716 20:30:48.958710 139892101641984 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14698)[0m 
[2m[36m(pid=14698)[0m W0716 20:30:48.958925 139892101641984 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14698)[0m 
[2m[36m(pid=14698)[0m W0716 20:30:48.959024 139892101641984 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14698)[0m 
[2m[36m(pid=14698)[0m I0716 20:30:48.959085 139892101641984 train.py:24] calling setup
[2m[36m(pid=14698)[0m I0716 20:30:48.959341 139892101641984 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14729)[0m W0716 20:30:48.964601 140323982214912 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14729)[0m 
[2m[36m(pid=14729)[0m W0716 20:30:48.964817 140323982214912 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14729)[0m 
[2m[36m(pid=14729)[0m W0716 20:30:48.964940 140323982214912 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14729)[0m 
[2m[36m(pid=14729)[0m I0716 20:30:48.965005 140323982214912 train.py:24] calling setup
[2m[36m(pid=14729)[0m I0716 20:30:48.965301 140323982214912 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14709)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14709)[0m W0716 20:30:49.125608 140131444225792 lazy_loader.py:50] 
[2m[36m(pid=14709)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.2019-07-16 20:30:49,394	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14709, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f71fa858588>

2019-07-16 20:30:49,397	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:51,434	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=16509, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f10cac80518>

2019-07-16 20:30:51,436	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:51,438	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:51,454	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14705, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7faed49d7588>

2019-07-16 20:30:51,456	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:51,457	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:53,889	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14719, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7efcbfe65588>

2019-07-16 20:30:53,890	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:53,892	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=14709)[0m For more information, please see:
[2m[36m(pid=14709)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14709)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14709)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14709)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14709)[0m 
[2m[36m(pid=16504)[0m W0716 20:30:49.102433 139899590280960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16504)[0m 
[2m[36m(pid=16504)[0m W0716 20:30:49.102691 139899590280960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16504)[0m 
[2m[36m(pid=16504)[0m W0716 20:30:49.102795 139899590280960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16504)[0m 
[2m[36m(pid=16504)[0m I0716 20:30:49.102858 139899590280960 train.py:24] calling setup
[2m[36m(pid=16504)[0m I0716 20:30:49.103160 139899590280960 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14709)[0m W0716 20:30:49.388169 140131444225792 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14709)[0m 
[2m[36m(pid=14709)[0m W0716 20:30:49.388393 140131444225792 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14709)[0m 
[2m[36m(pid=14709)[0m W0716 20:30:49.388496 140131444225792 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14709)[0m 
[2m[36m(pid=14709)[0m I0716 20:30:49.388559 140131444225792 train.py:24] calling setup
[2m[36m(pid=14709)[0m I0716 20:30:49.388822 140131444225792 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14705)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14705)[0m W0716 20:30:51.206991 140392043521792 lazy_loader.py:50] 
[2m[36m(pid=14705)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14705)[0m For more information, please see:
[2m[36m(pid=14705)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14705)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14705)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14705)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14705)[0m 
[2m[36m(pid=16509)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=16509)[0m W0716 20:30:51.234877 139714010621696 lazy_loader.py:50] 
[2m[36m(pid=16509)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=16509)[0m For more information, please see:
[2m[36m(pid=16509)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=16509)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=16509)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=16509)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=16509)[0m 
[2m[36m(pid=14705)[0m W0716 20:30:51.444399 140392043521792 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14705)[0m 
[2m[36m(pid=14705)[0m W0716 20:30:51.444616 140392043521792 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14705)[0m 
[2m[36m(pid=14705)[0m W0716 20:30:51.444716 140392043521792 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14705)[0m 
[2m[36m(pid=14705)[0m I0716 20:30:51.444777 140392043521792 train.py:24] calling setup
[2m[36m(pid=14705)[0m I0716 20:30:51.445024 140392043521792 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=16509)[0m W0716 20:30:51.429051 139714010621696 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=16509)[0m 
[2m[36m(pid=16509)[0m W0716 20:30:51.429261 139714010621696 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=16509)[0m 
[2m[36m(pid=16509)[0m W0716 20:30:51.429352 139714010621696 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=16509)[0m 
[2m[36m(pid=16509)[0m I0716 20:30:51.429406 139714010621696 train.py:24] calling setup
[2m[36m(pid=16509)[0m I0716 20:30:51.429532 139714010621696 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14719)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14719)[0m W0716 20:30:53.665774 139627941177088 lazy_loader.py:50] 
[2m[36m(pid=14719)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14719)[0m For more information, please see:
[2m[36m(pid=14719)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14719)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14719)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14719)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14719)[0m 
[2m[36m(pid=14731)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14731)[0m W0716 20:30:53.846527 140461842994944 lazy_loader.py:50] 
[2m[36m(pid=14731)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14731)[0m For more information, please see:
[2m[36m(pid=14731)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14731)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14731)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14731)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14731)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 10.0/40 CPUs, 2.0/8 GPUs
Memory usage on this node: 3.9/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'ERROR': 8, 'RUNNING': 2})
ERROR trials:
 - RayModel_0:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-34h2rikp5j/error_2019-07-16_20-30-48.txt
 - RayModel_1:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-34cwdpcpru/error_2019-07-16_20-30-48.txt
 - RayModel_2:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-34mtk1vlr2/error_2019-07-16_20-30-49.txt
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-34i4_c_d0f/error_2019-07-16_20-30-48.txt
 - RayModel_4:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-35rna3l0wt/error_2019-07-16_20-30-48.txt
 - RayModel_5:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-35xpqfjof8/error_2019-07-16_20-30-48.txt
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-35v02rcans/error_2019-07-16_20-30-48.txt
 - RayModel_7:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-350tzpwwnu/error_2019-07-16_20-30-49.txt
RUNNING trials:
 - RayModel_8:	RUNNING, 2 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_8_2019-07-16_20-30-48lukwohs0/error_2019-07-16_20-30-53.txt
 - RayModel_9:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_9_2019-07-16_20-30-48dmi6xizu/error_2019-07-16_20-30-51.txt
2019-07-16 20:30:54,076	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14731, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fbee90a5588>

2019-07-16 20:30:54,077	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:54,078	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
nohup: ignoring input
2019-07-16 20:30:56,562	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14702, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f3f0c314588>

2019-07-16 20:30:56,563	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:56,566	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:30:56,739	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14710, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f53dada56a0>

2019-07-16 20:30:56,742	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:30:56,742	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
WARNING: Logging before flag parsing goes to stderr.
W0716 20:30:58.084770 140628167816960 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0716 20:30:58.362361 140628167816960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:86: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0716 20:30:58.362542 140628167816960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:86: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0716 20:30:58.362634 140628167816960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:87: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0716 20:30:58.364526 140628167816960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/setup.py:76: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0716 20:30:58.364640 140628167816960 setup.py:76] Namespace(bs=512, checkpoint_freq=5, cpu=5.0, epochs=10, explore='cifar10', gpu=1.0, hp_policy='/data/zwy/hack_pba_tensorflow/schedules/hack.txt', hp_policy_epochs=10, local_dir='/data/zwy/hack_pba_tensorflow/results/resnet/', lr=0.1, model_name='resnet', name='resnet_train', no_aug=False, no_cutout=False, num_samples=10, resnet_size=18, restore=None, test_bs=512, use_hp_policy=True, wd=0.0005)
I0716 20:30:58.364751 140628167816960 setup.py:164] epochs: 10, lr: 0.1, wd: 0.0005
2019-07-16 20:30:58,365	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-16_20-30-58_365040_18767/logs.
2019-07-16 20:30:58,478	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:31140 to respond...
2019-07-16 20:30:58,620	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:35662 to respond...
2019-07-16 20:30:58,622	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2019-07-16 20:30:58,678	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-16_20-30-58_365040_18767/logs.
2019-07-16 20:30:58,679	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2019-07-16 20:30:58,679	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2019-07-16 20:30:58,840	INFO tune.py:61 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()
2019-07-16 20:30:58,840	INFO tune.py:233 -- Starting a new experiment.
W0716 20:30:59.203561 140628167816960 deprecation_wrapper.py:119] From /data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

W0716 20:30:59.204380 140628167816960 deprecation_wrapper.py:119] From /data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2019-07-16 20:30:59,340	WARNING util.py:64 -- The `start_trial` operation took 0.20099496841430664 seconds to complete, which may be a performance bottleneck.
2019-07-16 20:31:00,653	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14706, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f1937b63588>

2019-07-16 20:31:00,654	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=14719)[0m W0716 20:30:53.883404 139627941177088 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14719)[0m 
[2m[36m(pid=14719)[0m W0716 20:30:53.883671 139627941177088 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14719)[0m 
[2m[36m(pid=14719)[0m W0716 20:30:53.883783 139627941177088 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14719)[0m 
[2m[36m(pid=14719)[0m I0716 20:30:53.883839 139627941177088 train.py:24] calling setup
[2m[36m(pid=14719)[0m I0716 20:30:53.884109 139627941177088 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14731)[0m W0716 20:30:54.070052 140461842994944 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14731)[0m 
[2m[36m(pid=14731)[0m W0716 20:30:54.070222 140461842994944 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14731)[0m 
[2m[36m(pid=14731)[0m W0716 20:30:54.070322 140461842994944 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14731)[0m 
[2m[36m(pid=14731)[0m I0716 20:30:54.070377 140461842994944 train.py:24] calling setup
[2m[36m(pid=14731)[0m I0716 20:30:54.070595 140461842994944 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14702)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14702)[0m W0716 20:30:56.340907 139912635528960 lazy_loader.py:50] 
[2m[36m(pid=14702)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14702)[0m For more information, please see:
[2m[36m(pid=14702)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14702)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14702)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14702)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14702)[0m 
[2m[36m(pid=14710)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14710)[0m W0716 20:30:56.472403 140002043475712 lazy_loader.py:50] 
[2m[36m(pid=14710)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14710)[0m For more information, please see:
[2m[36m(pid=14710)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14710)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14710)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14710)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14710)[0m 
[2m[36m(pid=14702)[0m W0716 20:30:56.555767 139912635528960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14702)[0m 
[2m[36m(pid=14702)[0m W0716 20:30:56.555995 139912635528960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14702)[0m 
[2m[36m(pid=14702)[0m W0716 20:30:56.556090 139912635528960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14702)[0m 
[2m[36m(pid=14702)[0m I0716 20:30:56.556146 139912635528960 train.py:24] calling setup
[2m[36m(pid=14702)[0m I0716 20:30:56.556386 139912635528960 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14710)[0m W0716 20:30:56.729875 140002043475712 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14710)[0m 
[2m[36m(pid=14710)[0m W0716 20:30:56.731205 140002043475712 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14710)[0m 
[2m[36m(pid=14710)[0m W0716 20:30:56.731433 140002043475712 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14710)[0m 
[2m[36m(pid=14710)[0m I0716 20:30:56.731561 140002043475712 train.py:24] calling setup
[2m[36m(pid=14710)[0m I0716 20:30:56.732247 140002043475712 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=14706)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14706)[0m W0716 20:31:00.035189 139750197180160 lazy_loader.py:50] 
[2m[36m(pid=14706)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14706)[0m For more information, please see:
[2m[36m(pid=14706)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14706)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14706)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14706)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14706)[0m 
[2m[36m(pid=14735)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=14735)[0m W0716 20:31:00.582440 139928867960576 lazy_loader.py:50] 
[2m[36m(pid=14735)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=14735)[0m For more information, please see:
[2m[36m(pid=14735)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=14735)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=14735)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=14735)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=14735)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 5.0/40 CPUs, 1.0/8 GPUs
Memory usage on this node: 5.8/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'ERROR': 9, 'RUNNING': 1})
ERROR trials:
 - RayModel_0:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-34h2rikp5j/error_2019-07-16_20-30-48.txt
 - RayModel_1:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-34cwdpcpru/error_2019-07-16_20-30-48.txt
 - RayModel_2:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-34mtk1vlr2/error_2019-07-16_20-30-49.txt
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-34i4_c_d0f/error_2019-07-16_20-30-48.txt
 - RayModel_4:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-35rna3l0wt/error_2019-07-16_20-30-48.txt
 - RayModel_5:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-35xpqfjof8/error_2019-07-16_20-30-48.txt
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-35v02rcans/error_2019-07-16_20-30-48.txt
 - RayModel_7:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-350tzpwwnu/error_2019-07-16_20-30-49.txt
 - RayModel_8:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_8_2019-07-16_20-30-48lukwohs0/error_2019-07-16_20-31-00.txt
RUNNING trials:
 - RayModel_9:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_9_2019-07-16_20-30-48dmi6xizu/error_2019-07-16_20-30-56.txt
2019-07-16 20:31:00,827	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=14735, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f42d1454588>

2019-07-16 20:31:00,829	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=14706)[0m W0716 20:31:00.644232 139750197180160 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14706)[0m 
[2m[36m(pid=14706)[0m W0716 20:31:00.644593 139750197180160 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14706)[0m 
[2m[36m(pid=14706)[0m W0716 20:31:00.644783 139750197180160 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14706)[0m 
[2m[36m(pid=14706)[0m I0716 20:31:00.644898 139750197180160 train.py:24] calling setup
[2m[36m(pid=14706)[0m I0716 20:31:00.645488 139750197180160 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/40 CPUs, 0.0/8 GPUs
Memory usage on this node: 5.9/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'ERROR': 10})
ERROR trials:
 - RayModel_0:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-34h2rikp5j/error_2019-07-16_20-30-48.txt
 - RayModel_1:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-34cwdpcpru/error_2019-07-16_20-30-48.txt
 - RayModel_2:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-34mtk1vlr2/error_2019-07-16_20-30-49.txt
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-34i4_c_d0f/error_2019-07-16_20-30-48.txt
 - RayModel_4:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-35rna3l0wt/error_2019-07-16_20-30-48.txt
 - RayModel_5:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-35xpqfjof8/error_2019-07-16_20-30-48.txt
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-35v02rcans/error_2019-07-16_20-30-48.txt
 - RayModel_7:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-350tzpwwnu/error_2019-07-16_20-30-49.txt
 - RayModel_8:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_8_2019-07-16_20-30-48lukwohs0/error_2019-07-16_20-31-00.txt
 - RayModel_9:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_9_2019-07-16_20-30-48dmi6xizu/error_2019-07-16_20-31-00.txt

Traceback (most recent call last):
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 87, in <module>
    tf.app.run()
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 82, in main
    run_experiments({args.name: train_spec})
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/tune.py", line 333, in run_experiments
    raise_on_failed_trial=raise_on_failed_trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/tune.py", line 273, in run
    raise TuneError("Trials did not complete", errored_trials)
ray.tune.error.TuneError: ('Trials did not complete', [RayModel_0, RayModel_1, RayModel_2, RayModel_3, RayModel_4, RayModel_5, RayModel_6, RayModel_7, RayModel_8, RayModel_9])
[2m[36m(pid=14735)[0m W0716 20:31:00.822386 139928867960576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=14735)[0m 
[2m[36m(pid=14735)[0m W0716 20:31:00.822603 139928867960576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=14735)[0m 
[2m[36m(pid=14735)[0m W0716 20:31:00.822715 139928867960576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=14735)[0m 
[2m[36m(pid=14735)[0m I0716 20:31:00.822782 139928867960576 train.py:24] calling setup
[2m[36m(pid=14735)[0m I0716 20:31:00.823058 139928867960576 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
2019-07-16 20:31:03,503	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18996, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7ff84e970518>

2019-07-16 20:31:03,505	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,508	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:03,619	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19009, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fad4ede6588>

2019-07-16 20:31:03,621	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,622	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:03,640	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19003, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f74cdcde588>

2019-07-16 20:31:03,642	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,643	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/8 GPUs
Memory usage on this node: 4.3/270.4 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 5.0/40 CPUs, 1.0/8 GPUs
Memory usage on this node: 4.5/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - RayModel_1:	PENDING
 - RayModel_2:	PENDING
 - RayModel_3:	PENDING
 - RayModel_4:	PENDING
 - RayModel_5:	PENDING
 - RayModel_6:	PENDING
 - RayModel_7:	PENDING
 - RayModel_8:	PENDING
 - RayModel_9:	PENDING
RUNNING trials:
 - RayModel_0:	RUNNING

[2m[36m(pid=18996)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18996)[0m W0716 20:31:03.226521 140707622336256 lazy_loader.py:50] 
[2m[36m(pid=18996)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18996)[0m For more information, please see:
[2m[36m(pid=18996)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18996)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18996)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18996)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18996)[0m 
[2m[36m(pid=19009)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19009)[0m W0716 20:31:03.349925 140386322343680 lazy_loader.py:50] 
[2m[36m(pid=19009)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19009)[0m For more information, please see:
[2m[36m(pid=19009)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19009)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19009)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19009)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19009)[0m 
[2m[36m(pid=19003)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19003)[0m W0716 20:31:03.395826 140142821132032 lazy_loader.py:50] 
[2m[36m(pid=19003)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19003)[0m For more information, please see:
[2m[36m(pid=19003)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19003)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19003)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19003)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19003)[0m 
[2m[36m(pid=18977)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18977)[0m W0716 20:31:03.424598 140720031020800 lazy_loader.py:50] 
[2m[36m(pid=18977)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18977)[0m For more information, please see:
[2m[36m(pid=18977)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18977)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18977)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18977)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18977)[0m 
[2m[36m(pid=19001)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19001)[0m W0716 20:31:03.381207 140647393380096 lazy_loader.py:50] 
[2m[36m(pid=19001)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19001)[0m For more information, please see:
[2m[36m(pid=19001)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19001)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19001)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19001)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19001)[0m 
[2m[36m(pid=18994)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18994)[0m W0716 20:31:03.455716 140078737512192 lazy_loader.py:50] 
[2m[36m(pid=18994)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18994)[0m For more information, please see:
[2m[36m(pid=18994)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18994)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18994)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18994)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18994)[0m 
[2m[36m(pid=18980)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18980)[0m W0716 20:31:03.455716 140685329377024 lazy_loader.py:50] 
[2m[36m(pid=18980)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18980)[0m For more information, please see:
[2m[36m(pid=18980)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18980)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18980)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18980)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18980)[0m 
[2m[36m(pid=18996)[0m W0716 20:31:03.495170 140707622336256 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18996)[0m 
[2m[36m(pid=18996)[0m W0716 20:31:03.495470 140707622336256 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18996)[0m 
[2m[36m(pid=18996)[0m W0716 20:31:03.495632 140707622336256 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18996)[0m 
[2m[36m(pid=18996)[0m I0716 20:31:03.495726 140707622336256 train.py:24] calling setup
[2m[36m(pid=18996)[0m I0716 20:31:03.496165 140707622336256 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18989)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18989)[0m W0716 20:31:03.556525 140346099336960 lazy_loader.py:50] 
[2m[36m(pid=18989)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18989)[0m For more information, please see:
[2m[36m(pid=18989)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18989)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18989)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18989)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18989)[0m 
[2m[36m(pid=19009)[0m W0716 20:31:03.611625 140386322343680 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19009)[0m 
[2m[36m(pid=19009)[0m W0716 20:31:03.611962 140386322343680 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19009)[0m 
[2m[36m(pid=19009)[0m W0716 20:31:03.612121 140386322343680 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19009)[0m 
[2m[36m(pid=19009)[0m I0716 20:31:03.612218 140386322343680 train.py:24] calling setup
[2m[36m(pid=19009)[0m I0716 20:31:03.612468 140386322343680 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.02019-07-16 20:31:03,664	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19001, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fea48a8f588>

2019-07-16 20:31:03,667	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,668	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:03,695	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18977, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7ffb3030a5c0>

2019-07-16 20:31:03,696	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,697	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:03,716	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18994, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f65dc19f588>

2019-07-16 20:31:03,718	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,719	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:03,736	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18980, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7ff31dd16588>

2019-07-16 20:31:03,737	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,737	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:03,843	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18989, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fa3f15fc518>

2019-07-16 20:31:03,844	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:03,845	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=19003)[0m W0716 20:31:03.627453 140142821132032 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19003)[0m 
[2m[36m(pid=19003)[0m W0716 20:31:03.627876 140142821132032 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19003)[0m 
[2m[36m(pid=19003)[0m W0716 20:31:03.628090 140142821132032 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19003)[0m 
[2m[36m(pid=19003)[0m I0716 20:31:03.628221 140142821132032 train.py:24] calling setup
[2m[36m(pid=19003)[0m I0716 20:31:03.628544 140142821132032 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19001)[0m W0716 20:31:03.646786 140647393380096 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19001)[0m 
[2m[36m(pid=19001)[0m W0716 20:31:03.647110 140647393380096 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19001)[0m 
[2m[36m(pid=19001)[0m W0716 20:31:03.647290 140647393380096 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19001)[0m 
[2m[36m(pid=19001)[0m I0716 20:31:03.647409 140647393380096 train.py:24] calling setup
[2m[36m(pid=19001)[0m I0716 20:31:03.647717 140647393380096 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18994)[0m W0716 20:31:03.704208 140078737512192 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18994)[0m 
[2m[36m(pid=18994)[0m W0716 20:31:03.704518 140078737512192 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18994)[0m 
[2m[36m(pid=18994)[0m W0716 20:31:03.704687 140078737512192 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18994)[0m 
[2m[36m(pid=18994)[0m I0716 20:31:03.704801 140078737512192 train.py:24] calling setup
[2m[36m(pid=18994)[0m I0716 20:31:03.705364 140078737512192 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18977)[0m W0716 20:31:03.688163 140720031020800 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18977)[0m 
[2m[36m(pid=18977)[0m W0716 20:31:03.688707 140720031020800 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18977)[0m 
[2m[36m(pid=18977)[0m W0716 20:31:03.689042 140720031020800 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18977)[0m 
[2m[36m(pid=18977)[0m I0716 20:31:03.689187 140720031020800 train.py:24] calling setup
[2m[36m(pid=18977)[0m I0716 20:31:03.689578 140720031020800 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18980)[0m W0716 20:31:03.713994 140685329377024 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18980)[0m 
[2m[36m(pid=18980)[0m W0716 20:31:03.714328 140685329377024 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18980)[0m 
[2m[36m(pid=18980)[0m W0716 20:31:03.714516 140685329377024 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18980)[0m 
[2m[36m(pid=18980)[0m I0716 20:31:03.714640 140685329377024 train.py:24] calling setup
[2m[36m(pid=18980)[0m I0716 20:31:03.715188 140685329377024 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18989)[0m W0716 20:31:03.836005 140346099336960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18989)[0m 
[2m[36m(pid=18989)[0m W0716 20:31:03.836350 140346099336960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18989)[0m 
[2m[36m(pid=18989)[0m W0716 20:31:03.836502 140346099336960 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18989)[0m 
[2m[36m(pid=18989)[0m I0716 20:31:03.836571 140346099336960 train.py:24] calling setup
[2m[36m(pid=18989)[0m I0716 20:31:03.836960 140346099336960 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20759)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20759)[0m W0716 20:31:06.554383 139904907118336 lazy_loader.py:50] 
[2m[36m(pid=20759)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20759)[0m For more information, please see:
[2m[36m(pid=20759)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20759)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20759)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20759)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20759)[0m 
[2m[36m(pid=20780)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20780)[0m W0716 20:31:06.620846 140328141678336 lazy_loader.py:50] 
[2m[36m(pid=20780)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20780)[0m For more information, please see:
[2m[36m(pid=20780)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20780)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20780)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20780)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20780)[0m 
[2m[36m(pid=20773)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20775)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20775)[0m W0716 20:31:06.643365 139710604773120 lazy_loader.py:50] 
[2m[36m(pid=20775)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20775)[0m For more information, please see:2019-07-16 20:31:06,848	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20759, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f3d69097518>

2019-07-16 20:31:06,849	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,852	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:06,894	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20780, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f9fc3aa1518>

2019-07-16 20:31:06,895	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,896	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:06,911	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20773, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f3f6b9f0588>

2019-07-16 20:31:06,912	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,913	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=20775)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20775)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20775)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20775)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20775)[0m 
[2m[36m(pid=20773)[0m W0716 20:31:06.643865 139913607943936 lazy_loader.py:50] 
[2m[36m(pid=20773)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20773)[0m For more information, please see:
[2m[36m(pid=20773)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20773)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20773)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20773)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20773)[0m 
[2m[36m(pid=20763)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20763)[0m W0716 20:31:06.652951 139633877325568 lazy_loader.py:50] 
[2m[36m(pid=20763)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20763)[0m For more information, please see:
[2m[36m(pid=20763)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20763)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20763)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20763)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20763)[0m 
[2m[36m(pid=20756)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20756)[0m W0716 20:31:06.664601 140155845179136 lazy_loader.py:50] 
[2m[36m(pid=20756)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20756)[0m For more information, please see:
[2m[36m(pid=20756)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20756)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20756)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20756)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20756)[0m 
[2m[36m(pid=20761)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20761)[0m W0716 20:31:06.728494 140648593950464 lazy_loader.py:50] 
[2m[36m(pid=20761)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20761)[0m For more information, please see:
[2m[36m(pid=20761)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20761)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20761)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20761)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20761)[0m 
[2m[36m(pid=18981)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18981)[0m W0716 20:31:06.813530 140364493567744 lazy_loader.py:50] 
[2m[36m(pid=18981)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18981)[0m For more information, please see:
[2m[36m(pid=18981)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18981)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18981)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18981)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18981)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40.0/40 CPUs, 8.0/8 GPUs
Memory usage on this node: 5.7/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'RUNNING': 8, 'PENDING': 2})
PENDING trials:
 - RayModel_8:	PENDING
 - RayModel_9:	PENDING
RUNNING trials:
 - RayModel_0:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-59spcrer22/error_2019-07-16_20-31-03.txt
 - RayModel_1:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-59sm49bip3/error_2019-07-16_20-31-03.txt
 - RayModel_2:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-59j22ogodp/error_2019-07-16_20-31-03.txt
 - RayModel_3:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-59ygh4em_w/error_2019-07-16_20-31-03.txt
 - RayModel_4:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-59kvo67rtj/error_2019-07-16_20-31-03.txt
 - RayModel_5:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-59p_put295/error_2019-07-16_20-31-03.txt
 - RayModel_6:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-594a_6lpw2/error_2019-07-16_20-31-03.txt
 - RayModel_7:	RUNNING, 2 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-593tudowne/error_2019-07-16_20-31-06.txt

[2m[36m(pid=20759)[0m W0716 20:31:06.840515 139904907118336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20759)[0m 
[2m[36m(pid=20759)[0m W0716 20:31:06.840808 139904907118336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20759)[0m 
[2m[36m(pid=20759)[0m W0716 20:31:06.840977 139904907118336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20759)[0m 
[2m[36m(pid=20759)[0m I0716 20:31:06.841074 139904907118336 train.py:24] calling setup
[2m[36m(pid=20759)[0m I0716 20:31:06.841568 139904907118336 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20763)[0m W0716 20:31:06.901841 139633877325568 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20763)[0m 
[2m[36m(pid=20763)[0m W0716 20:31:06.902129 139633877325568 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20763)[0m 
[2m[36m(pid=20763)[0m W0716 20:31:06.902329 139633877325568 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20763)[0m 
[2m[36m(pid=20763)[0m I0716 20:31:06.902433 139633877325568 train.py:24] calling setup
[2m[36m(pid=20763)[0m I0716 20:31:06.902841 139633877325568 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20773)[0m W0716 20:31:06.893529 139913607943936 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20773)[0m 
[2m[36m(pid=20773)[0m W0716 20:31:06.893877 139913607943936 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20773)[0m 
[2m[36m(pid=20773)[0m W0716 20:31:06.894042 139913607943936 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.2019-07-16 20:31:06,932	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20756, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f77a5612588>

2019-07-16 20:31:06,933	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,934	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:06,948	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20763, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7efe46602518>

2019-07-16 20:31:06,949	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,950	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:06,966	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20775, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f102bb4f588>

2019-07-16 20:31:06,967	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,968	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:06,986	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20761, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fea90317630>

2019-07-16 20:31:06,988	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:06,989	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:07,066	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18981, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fa8448415c0>

2019-07-16 20:31:07,068	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:07,069	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:09,957	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18997, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fdfe72a3588>

2019-07-16 20:31:09,959	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:09,962	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=20773)[0m 
[2m[36m(pid=20773)[0m I0716 20:31:06.894140 139913607943936 train.py:24] calling setup
[2m[36m(pid=20773)[0m I0716 20:31:06.894701 139913607943936 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20775)[0m W0716 20:31:06.921571 139710604773120 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20775)[0m 
[2m[36m(pid=20775)[0m W0716 20:31:06.921945 139710604773120 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20775)[0m 
[2m[36m(pid=20775)[0m W0716 20:31:06.922079 139710604773120 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20775)[0m 
[2m[36m(pid=20775)[0m I0716 20:31:06.922165 139710604773120 train.py:24] calling setup
[2m[36m(pid=20775)[0m I0716 20:31:06.922547 139710604773120 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20756)[0m W0716 20:31:06.895920 140155845179136 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20756)[0m 
[2m[36m(pid=20756)[0m W0716 20:31:06.896361 140155845179136 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20756)[0m 
[2m[36m(pid=20756)[0m W0716 20:31:06.896592 140155845179136 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20756)[0m 
[2m[36m(pid=20756)[0m I0716 20:31:06.896717 140155845179136 train.py:24] calling setup
[2m[36m(pid=20756)[0m I0716 20:31:06.897387 140155845179136 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20780)[0m W0716 20:31:06.887349 140328141678336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20780)[0m 
[2m[36m(pid=20780)[0m W0716 20:31:06.887636 140328141678336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20780)[0m 
[2m[36m(pid=20780)[0m W0716 20:31:06.887786 140328141678336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20780)[0m 
[2m[36m(pid=20780)[0m I0716 20:31:06.887884 140328141678336 train.py:24] calling setup
[2m[36m(pid=20780)[0m I0716 20:31:06.888349 140328141678336 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20761)[0m W0716 20:31:06.958492 140648593950464 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20761)[0m 
[2m[36m(pid=20761)[0m W0716 20:31:06.958872 140648593950464 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20761)[0m 
[2m[36m(pid=20761)[0m W0716 20:31:06.959057 140648593950464 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20761)[0m 
[2m[36m(pid=20761)[0m I0716 20:31:06.959166 140648593950464 train.py:24] calling setup
[2m[36m(pid=20761)[0m I0716 20:31:06.959955 140648593950464 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18981)[0m W0716 20:31:07.057704 140364493567744 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18981)[0m 
[2m[36m(pid=18981)[0m W0716 20:31:07.058103 140364493567744 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18981)[0m 
[2m[36m(pid=18981)[0m W0716 20:31:07.058343 140364493567744 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18981)[0m 
[2m[36m(pid=18981)[0m I0716 20:31:07.058472 140364493567744 train.py:24] calling setup
[2m[36m(pid=18981)[0m I0716 20:31:07.059003 140364493567744 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18997)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18997)[0m W0716 20:31:09.686047 140603544979200 lazy_loader.py:50] 
[2m[36m(pid=18997)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18997)[0m For more information, please see:
[2m[36m(pid=18997)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18997)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18997)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18997)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18997)[0m 
[2m[36m(pid=20778)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20778)[0m W0716 20:31:09.802690 140687412496128 lazy_loader.py:50] 
[2m[36m(pid=20778)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20778)[0m For more information, please see:
[2m[36m(pid=20778)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20778)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20778)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20778)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20778)[0m 
[2m[36m(pid=20771)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20771)[0m W0716 20:31:09.861763 140342354011904 lazy_loader.py:50] 
[2m[36m(pid=20771)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20771)[0m For more information, please see:
[2m[36m(pid=20771)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20771)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20771)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20771)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20771)[0m 
[2m[36m(pid=18997)[0m W0716 20:31:09.947245 140603544979200 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18997)[0m 
[2m[36m(pid=18997)[0m W0716 20:31:09.947659 140603544979200 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.2019-07-16 20:31:10,066	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20778, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7ff36e1a4588>

2019-07-16 20:31:10,068	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,069	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:10,126	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20771, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fa342e32518>

2019-07-16 20:31:10,128	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,129	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:10,341	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18985, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f4c09757588>

2019-07-16 20:31:10,342	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,343	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:10,375	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19005, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fe41210a588>

2019-07-16 20:31:10,376	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,377	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:10,392	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20788, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fcd31734588>

2019-07-16 20:31:10,393	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,393	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:10,415	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18991, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fc018c4b588>

2019-07-16 20:31:10,417	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,418	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=18997)[0m 
[2m[36m(pid=18997)[0m W0716 20:31:09.947911 140603544979200 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18997)[0m 
[2m[36m(pid=18997)[0m I0716 20:31:09.948041 140603544979200 train.py:24] calling setup
[2m[36m(pid=18997)[0m I0716 20:31:09.948859 140603544979200 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20778)[0m W0716 20:31:10.056695 140687412496128 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20778)[0m 
[2m[36m(pid=20778)[0m W0716 20:31:10.057075 140687412496128 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20778)[0m 
[2m[36m(pid=20778)[0m W0716 20:31:10.057295 140687412496128 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20778)[0m 
[2m[36m(pid=20778)[0m I0716 20:31:10.057418 140687412496128 train.py:24] calling setup
[2m[36m(pid=20778)[0m I0716 20:31:10.058134 140687412496128 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18991)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18991)[0m W0716 20:31:10.074800 140466537600768 lazy_loader.py:50] 
[2m[36m(pid=18991)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18991)[0m For more information, please see:
[2m[36m(pid=18991)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18991)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18991)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18991)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18991)[0m 
[2m[36m(pid=19005)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19005)[0m W0716 20:31:10.111804 140620909623040 lazy_loader.py:50] 
[2m[36m(pid=19005)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19005)[0m For more information, please see:
[2m[36m(pid=19005)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19005)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19005)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19005)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19005)[0m 
[2m[36m(pid=18985)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18985)[0m W0716 20:31:10.094993 139967728436992 lazy_loader.py:50] 
[2m[36m(pid=18985)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18985)[0m For more information, please see:
[2m[36m(pid=18985)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18985)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18985)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18985)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18985)[0m 
[2m[36m(pid=20788)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20788)[0m W0716 20:31:10.108624 140523187017472 lazy_loader.py:50] 
[2m[36m(pid=20788)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20788)[0m For more information, please see:
[2m[36m(pid=20788)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20788)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20788)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20788)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20788)[0m 
[2m[36m(pid=20771)[0m W0716 20:31:10.118440 140342354011904 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20771)[0m 
[2m[36m(pid=20771)[0m W0716 20:31:10.118806 140342354011904 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20771)[0m 
[2m[36m(pid=20771)[0m W0716 20:31:10.118975 140342354011904 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20771)[0m 
[2m[36m(pid=20771)[0m I0716 20:31:10.119094 140342354011904 train.py:24] calling setup
[2m[36m(pid=20771)[0m I0716 20:31:10.119622 140342354011904 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18976)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18976)[0m W0716 20:31:10.142194 140024120440576 lazy_loader.py:50] 
[2m[36m(pid=18976)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18976)[0m For more information, please see:
[2m[36m(pid=18976)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18976)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18976)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18976)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18976)[0m 
[2m[36m(pid=18985)[0m W0716 20:31:10.333873 139967728436992 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18985)[0m 
[2m[36m(pid=18985)[0m W0716 20:31:10.334144 139967728436992 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18985)[0m 
[2m[36m(pid=18985)[0m W0716 20:31:10.334869 139967728436992 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18985)[0m 
[2m[36m(pid=18985)[0m I0716 20:31:10.334974 139967728436992 train.py:24] calling setup
[2m[36m(pid=18985)[0m I0716 20:31:10.335276 139967728436992 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18991)[0m W0716 20:31:10.379907 140466537600768 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18991)[0m 
[2m[36m(pid=18991)[0m W0716 20:31:10.380284 140466537600768 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18991)[0m 
[2m[36m(pid=18991)[0m W0716 20:31:10.380472 140466537600768 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18991)[0m 
[2m[36m(pid=18991)[0m I0716 20:31:10.380600 140466537600768 train.py:24] calling setup
[2m[36m(pid=18991)[0m I0716 20:31:10.381157 140466537600768 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.02019-07-16 20:31:10,456	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18976, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f591eadc588>

2019-07-16 20:31:10,457	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:10,457	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:13,289	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18992, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7fa09e1d6588>

2019-07-16 20:31:13,290	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=19005)[0m W0716 20:31:10.369114 140620909623040 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19005)[0m 
[2m[36m(pid=19005)[0m W0716 20:31:10.369358 140620909623040 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19005)[0m 
[2m[36m(pid=19005)[0m W0716 20:31:10.369489 140620909623040 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19005)[0m 
[2m[36m(pid=19005)[0m I0716 20:31:10.369568 140620909623040 train.py:24] calling setup
[2m[36m(pid=19005)[0m I0716 20:31:10.369951 140620909623040 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20788)[0m W0716 20:31:10.367146 140523187017472 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20788)[0m 
[2m[36m(pid=20788)[0m W0716 20:31:10.367555 140523187017472 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20788)[0m 
[2m[36m(pid=20788)[0m W0716 20:31:10.367764 140523187017472 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20788)[0m 
[2m[36m(pid=20788)[0m I0716 20:31:10.367887 140523187017472 train.py:24] calling setup
[2m[36m(pid=20788)[0m I0716 20:31:10.368523 140523187017472 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18976)[0m W0716 20:31:10.449076 140024120440576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18976)[0m 
[2m[36m(pid=18976)[0m W0716 20:31:10.449305 140024120440576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18976)[0m 
[2m[36m(pid=18976)[0m W0716 20:31:10.449419 140024120440576 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18976)[0m 
[2m[36m(pid=18976)[0m I0716 20:31:10.449489 140024120440576 train.py:24] calling setup
[2m[36m(pid=18976)[0m I0716 20:31:10.449791 140024120440576 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18992)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18992)[0m W0716 20:31:13.005817 140330999990016 lazy_loader.py:50] 
[2m[36m(pid=18992)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18992)[0m For more information, please see:
[2m[36m(pid=18992)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18992)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18992)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18992)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18992)[0m 
[2m[36m(pid=20768)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20768)[0m W0716 20:31:13.036279 140104548435712 lazy_loader.py:50] 
[2m[36m(pid=20768)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20768)[0m For more information, please see:
[2m[36m(pid=20768)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20768)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20768)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20768)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20768)[0m 
[2m[36m(pid=20753)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20753)[0m W0716 20:31:13.172658 139770168760064 lazy_loader.py:50] 
[2m[36m(pid=20753)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20753)[0m For more information, please see:
[2m[36m(pid=20753)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20753)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20753)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20753)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20753)[0m 
[2m[36m(pid=18992)[0m W0716 20:31:13.281245 140330999990016 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18992)[0m 
[2m[36m(pid=18992)[0m W0716 20:31:13.281624 140330999990016 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18992)[0m 
[2m[36m(pid=18992)[0m W0716 20:31:13.281839 140330999990016 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18992)[0m 
[2m[36m(pid=18992)[0m I0716 20:31:13.281958 140330999990016 train.py:24] calling setup
[2m[36m(pid=18992)[0m I0716 20:31:13.282522 140330999990016 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=20786)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=20786)[0m W0716 20:31:13.268480 139952072161024 lazy_loader.py:50] 
[2m[36m(pid=20786)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=20786)[0m For more information, please see:
[2m[36m(pid=20786)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=20786)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=20786)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=20786)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=20786)[0m 
[2m[36m(pid=20768)[0m W0716 20:31:13.284548 140104548435712 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20768)[0m 
[2m[36m(pid=20768)[0m W0716 20:31:13.284893 140104548435712 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20768)[0m 
[2m[36m(pid=20768)[0m W0716 20:31:13.285100 140104548435712 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20768)[0m 
[2m[36m(pid=20768)[0m I0716 20:31:13.285304 140104548435712 train.py:24] calling setup
[2m[36m(pid=20768)[0m I0716 20:31:13.285858 140104548435712 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 35.0/40 CPUs, 7.0/8 GPUs
Memory usage on this node: 5.2/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'RUNNING': 7, 'ERROR': 1, 'PENDING': 2})
ERROR trials:
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-59ygh4em_w/error_2019-07-16_20-31-13.txt
PENDING trials:
 - RayModel_8:	PENDING
 - RayModel_9:	PENDING
RUNNING trials:
 - RayModel_0:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-59spcrer22/error_2019-07-16_20-31-10.txt
 - RayModel_1:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-59sm49bip3/error_2019-07-16_20-31-10.txt
 - RayModel_2:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-59j22ogodp/error_2019-07-16_20-31-10.txt
 - RayModel_4:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-59kvo67rtj/error_2019-07-16_20-31-10.txt
 - RayModel_5:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-59p_put295/error_2019-07-16_20-31-10.txt
 - RayModel_6:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-594a_6lpw2/error_2019-07-16_20-31-10.txt
 - RayModel_7:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-593tudowne/error_2019-07-16_20-31-09.txt
2019-07-16 20:31:13,314	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20768, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f6bb8a16588>

2019-07-16 20:31:13,316	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_7. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:13,443	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20753, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f1dde0a4588>

2019-07-16 20:31:13,445	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:13,530	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=20786, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f483851d588>

2019-07-16 20:31:13,531	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_6. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:13,622	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19013, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f6ea6d6d588>

2019-07-16 20:31:13,623	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_4. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:13,696	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18993, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f21d258f588>

2019-07-16 20:31:13,697	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_5. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:13,704	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19015, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f2506796588>

2019-07-16 20:31:13,705	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_1. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:13,785	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18990, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f4163cfc588>

2019-07-16 20:31:13,787	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=19013)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19013)[0m W0716 20:31:13.361593 140116465059584 lazy_loader.py:50] 
[2m[36m(pid=19013)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19013)[0m For more information, please see:
[2m[36m(pid=19013)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19013)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19013)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19013)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19013)[0m 
[2m[36m(pid=18993)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18993)[0m W0716 20:31:13.430137 139787233044224 lazy_loader.py:50] 
[2m[36m(pid=18993)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18993)[0m For more information, please see:
[2m[36m(pid=18993)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18993)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18993)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18993)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18993)[0m 
[2m[36m(pid=19015)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19015)[0m W0716 20:31:13.429757 139800174466816 lazy_loader.py:50] 
[2m[36m(pid=19015)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19015)[0m For more information, please see:
[2m[36m(pid=19015)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19015)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19015)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19015)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19015)[0m 
[2m[36m(pid=20753)[0m W0716 20:31:13.436555 139770168760064 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20753)[0m 
[2m[36m(pid=20753)[0m W0716 20:31:13.436771 139770168760064 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20753)[0m 
[2m[36m(pid=20753)[0m W0716 20:31:13.436882 139770168760064 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20753)[0m 
[2m[36m(pid=20753)[0m I0716 20:31:13.436951 139770168760064 train.py:24] calling setup
[2m[36m(pid=20753)[0m I0716 20:31:13.437140 139770168760064 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18990)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18990)[0m W0716 20:31:13.553951 139922133870336 lazy_loader.py:50] 
[2m[36m(pid=18990)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18990)[0m For more information, please see:
[2m[36m(pid=18990)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18990)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18990)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18990)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18990)[0m 
[2m[36m(pid=20786)[0m W0716 20:31:13.523919 139952072161024 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=20786)[0m 
[2m[36m(pid=20786)[0m W0716 20:31:13.524129 139952072161024 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=20786)[0m 
[2m[36m(pid=20786)[0m W0716 20:31:13.524238 139952072161024 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=20786)[0m 
[2m[36m(pid=20786)[0m I0716 20:31:13.524305 139952072161024 train.py:24] calling setup
[2m[36m(pid=20786)[0m I0716 20:31:13.524584 139952072161024 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19013)[0m W0716 20:31:13.616146 140116465059584 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19013)[0m 
[2m[36m(pid=19013)[0m W0716 20:31:13.616388 140116465059584 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19013)[0m 
[2m[36m(pid=19013)[0m W0716 20:31:13.616582 140116465059584 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19013)[0m 
[2m[36m(pid=19013)[0m I0716 20:31:13.616696 140116465059584 train.py:24] calling setup
[2m[36m(pid=19013)[0m I0716 20:31:13.617028 140116465059584 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18993)[0m W0716 20:31:13.690732 139787233044224 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18993)[0m 
[2m[36m(pid=18993)[0m W0716 20:31:13.690977 139787233044224 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18993)[0m 
[2m[36m(pid=18993)[0m W0716 20:31:13.691087 139787233044224 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18993)[0m 
[2m[36m(pid=18993)[0m I0716 20:31:13.691155 139787233044224 train.py:24] calling setup
[2m[36m(pid=18993)[0m I0716 20:31:13.691468 139787233044224 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19015)[0m W0716 20:31:13.692077 139800174466816 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19015)[0m 
[2m[36m(pid=19015)[0m W0716 20:31:13.692278 139800174466816 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19015)[0m 
[2m[36m(pid=19015)[0m W0716 20:31:13.692389 139800174466816 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19015)[0m 
[2m[36m(pid=19015)[0m I0716 20:31:13.692460 139800174466816 train.py:24] calling setup
[2m[36m(pid=19015)[0m I0716 20:31:13.692630 139800174466816 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18990)[0m W0716 20:31:13.778783 139922133870336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.2019-07-16 20:31:15,899	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19010, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f2cdd762588>

2019-07-16 20:31:15,900	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:15,903	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:16,002	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18983, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f1de58dd588>

2019-07-16 20:31:16,004	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:16,005	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:18,417	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18979, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f2aa76b5588>

2019-07-16 20:31:18,420	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:18,422	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.

[2m[36m(pid=18990)[0m 
[2m[36m(pid=18990)[0m W0716 20:31:13.778981 139922133870336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18990)[0m 
[2m[36m(pid=18990)[0m W0716 20:31:13.779077 139922133870336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18990)[0m 
[2m[36m(pid=18990)[0m I0716 20:31:13.779135 139922133870336 train.py:24] calling setup
[2m[36m(pid=18990)[0m I0716 20:31:13.779381 139922133870336 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19010)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19010)[0m W0716 20:31:15.633283 139834583140096 lazy_loader.py:50] 
[2m[36m(pid=19010)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19010)[0m For more information, please see:
[2m[36m(pid=19010)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19010)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19010)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19010)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19010)[0m 
[2m[36m(pid=18983)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18983)[0m W0716 20:31:15.763412 139770261096192 lazy_loader.py:50] 
[2m[36m(pid=18983)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18983)[0m For more information, please see:
[2m[36m(pid=18983)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18983)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18983)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18983)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18983)[0m 
[2m[36m(pid=19010)[0m W0716 20:31:15.893375 139834583140096 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19010)[0m 
[2m[36m(pid=19010)[0m W0716 20:31:15.893606 139834583140096 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19010)[0m 
[2m[36m(pid=19010)[0m W0716 20:31:15.893730 139834583140096 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19010)[0m 
[2m[36m(pid=19010)[0m I0716 20:31:15.893805 139834583140096 train.py:24] calling setup
[2m[36m(pid=19010)[0m I0716 20:31:15.894078 139834583140096 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18983)[0m W0716 20:31:15.996621 139770261096192 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18983)[0m 
[2m[36m(pid=18983)[0m W0716 20:31:15.996878 139770261096192 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18983)[0m 
[2m[36m(pid=18983)[0m W0716 20:31:15.997015 139770261096192 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18983)[0m 
[2m[36m(pid=18983)[0m I0716 20:31:15.997075 139770261096192 train.py:24] calling setup
[2m[36m(pid=18983)[0m I0716 20:31:15.997331 139770261096192 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18979)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18979)[0m W0716 20:31:18.181522 139825086023424 lazy_loader.py:50] 
[2m[36m(pid=18979)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18979)[0m For more information, please see:
[2m[36m(pid=18979)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18979)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18979)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18979)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18979)[0m 
[2m[36m(pid=19008)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19008)[0m W0716 20:31:18.301074 140026931525376 lazy_loader.py:50] 
[2m[36m(pid=19008)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19008)[0m For more information, please see:
[2m[36m(pid=19008)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19008)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19008)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19008)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19008)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 10.0/40 CPUs, 2.0/8 GPUs
Memory usage on this node: 3.9/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'ERROR': 8, 'RUNNING': 2})
ERROR trials:
 - RayModel_0:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-59spcrer22/error_2019-07-16_20-31-13.txt
 - RayModel_1:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-59sm49bip3/error_2019-07-16_20-31-13.txt
 - RayModel_2:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-59j22ogodp/error_2019-07-16_20-31-13.txt
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-59ygh4em_w/error_2019-07-16_20-31-13.txt
 - RayModel_4:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-59kvo67rtj/error_2019-07-16_20-31-13.txt
 - RayModel_5:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-59p_put295/error_2019-07-16_20-31-13.txt
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-594a_6lpw2/error_2019-07-16_20-31-13.txt
 - RayModel_7:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-593tudowne/error_2019-07-16_20-31-13.txt
RUNNING trials:
 - RayModel_8:	RUNNING, 2 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_8_2019-07-16_20-31-13spimzt23/error_2019-07-16_20-31-18.txt
 - RayModel_9:	RUNNING, 1 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_9_2019-07-16_20-31-13ssedk4vg/error_2019-07-16_20-31-16.txt

[2m[36m(pid=18979)[0m W0716 20:31:18.412455 139825086023424 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18979)[0m 
[2m[36m(pid=18979)[0m W0716 20:31:18.412678 139825086023424 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18979)[0m 2019-07-16 20:31:18,540	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19008, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f59a64f3588>

2019-07-16 20:31:18,542	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:18,543	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:21,063	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19000, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f5c342ed588>

2019-07-16 20:31:21,065	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:21,067	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:21,086	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18998, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f29b74ab5c0>

2019-07-16 20:31:21,087	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-16 20:31:21,087	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-16 20:31:23,688	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=19004, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f4e080a4588>

2019-07-16 20:31:23,691	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_8. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=18979)[0m W0716 20:31:18.412776 139825086023424 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18979)[0m 
[2m[36m(pid=18979)[0m I0716 20:31:18.412832 139825086023424 train.py:24] calling setup
[2m[36m(pid=18979)[0m I0716 20:31:18.413058 139825086023424 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19008)[0m W0716 20:31:18.534491 140026931525376 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19008)[0m 
[2m[36m(pid=19008)[0m W0716 20:31:18.534774 140026931525376 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19008)[0m 
[2m[36m(pid=19008)[0m W0716 20:31:18.534898 140026931525376 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19008)[0m 
[2m[36m(pid=19008)[0m I0716 20:31:18.534992 140026931525376 train.py:24] calling setup
[2m[36m(pid=19008)[0m I0716 20:31:18.535313 140026931525376 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19000)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19000)[0m W0716 20:31:20.824004 140037901469440 lazy_loader.py:50] 
[2m[36m(pid=19000)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19000)[0m For more information, please see:
[2m[36m(pid=19000)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19000)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19000)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19000)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19000)[0m 
[2m[36m(pid=18998)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18998)[0m W0716 20:31:20.868573 139820321191680 lazy_loader.py:50] 
[2m[36m(pid=18998)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18998)[0m For more information, please see:
[2m[36m(pid=18998)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18998)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18998)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18998)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18998)[0m 
[2m[36m(pid=19000)[0m W0716 20:31:21.057624 140037901469440 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19000)[0m 
[2m[36m(pid=19000)[0m W0716 20:31:21.057821 140037901469440 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19000)[0m 
[2m[36m(pid=19000)[0m W0716 20:31:21.057931 140037901469440 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19000)[0m 
[2m[36m(pid=19000)[0m I0716 20:31:21.057986 140037901469440 train.py:24] calling setup
[2m[36m(pid=19000)[0m I0716 20:31:21.058194 140037901469440 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18998)[0m W0716 20:31:21.080861 139820321191680 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18998)[0m 
[2m[36m(pid=18998)[0m W0716 20:31:21.081119 139820321191680 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18998)[0m 
[2m[36m(pid=18998)[0m W0716 20:31:21.081250 139820321191680 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18998)[0m 
[2m[36m(pid=18998)[0m I0716 20:31:21.081431 139820321191680 train.py:24] calling setup
[2m[36m(pid=18998)[0m I0716 20:31:21.081707 139820321191680 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=19004)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=19004)[0m W0716 20:31:23.411633 139977031022336 lazy_loader.py:50] 
[2m[36m(pid=19004)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=19004)[0m For more information, please see:
[2m[36m(pid=19004)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=19004)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=19004)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=19004)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=19004)[0m 
[2m[36m(pid=18978)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=18978)[0m W0716 20:31:23.436741 139697188763392 lazy_loader.py:50] 
[2m[36m(pid=18978)[0m The TensorFlow contrib module will not be included in TensorFlow 2.0.
[2m[36m(pid=18978)[0m For more information, please see:
[2m[36m(pid=18978)[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
[2m[36m(pid=18978)[0m   * https://github.com/tensorflow/addons
[2m[36m(pid=18978)[0m   * https://github.com/tensorflow/io (for I/O related ops)
[2m[36m(pid=18978)[0m If you depend on functionality not listed there, please file an issue.
[2m[36m(pid=18978)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 5.0/40 CPUs, 1.0/8 GPUs
Memory usage on this node: 3.9/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'ERROR': 9, 'RUNNING': 1})
ERROR trials:
 - RayModel_0:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-59spcrer22/error_2019-07-16_20-31-13.txt
 - RayModel_1:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-59sm49bip3/error_2019-07-16_20-31-13.txt
 - RayModel_2:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-59j22ogodp/error_2019-07-16_20-31-13.txt
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-59ygh4em_w/error_2019-07-16_20-31-13.txt
 - RayModel_4:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-59kvo67rtj/error_2019-07-16_20-31-13.txt
 - RayModel_5:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-59p_put295/error_2019-07-16_20-31-13.txt
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-594a_6lpw2/error_2019-07-16_20-31-13.txt
 - RayModel_7:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-593tudowne/error_2019-07-16_20-31-13.txt
 - RayModel_8:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_8_2019-07-16_20-31-13spimzt23/error_2019-07-16_20-31-23.txt
RUNNING trials:
 - RayModel_9:	RUNNING, 3 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_9_2019-07-16_20-31-13ssedk4vg/error_2019-07-16_20-31-21.txt
2019-07-16 20:31:23,701	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_RayModel:train()[39m (pid=18978, host=GPU-237)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 26, in _setup
    self.trainer = ModelTrainer(self.hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/model.py", line 332, in __init__
    self.dataset = data_utils.DataSet(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 66, in __init__
    self.parse_policy(hparams)
  File "/data/zwy/hack_pba_tensorflow/pba/data_utils.py", line 95, in parse_policy
    hparams.hp_policy_epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 77, in parse_log_schedule
    policy = parse_log(file_path, epochs)
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in parse_log
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/zwy/hack_pba_tensorflow/pba/utils.py", line 28, in <listcomp>
    raw_policy = [ast.literal_eval(line) for line in raw_policy]
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 61, in _convert
    return list(map(_convert, node.elts))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 66, in _convert
    in zip(node.keys, node.values))
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 65, in <genexpr>
    return dict((_convert(k), _convert(v)) for k, v
  File "/data/anaconda3/envs/pba/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
ValueError: malformed node or string: <_ast.Name object at 0x7f0d0bff2588>

2019-07-16 20:31:23,703	INFO ray_trial_executor.py:187 -- Destroying actor for trial RayModel_9. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

[2m[36m(pid=19004)[0m W0716 20:31:23.683662 139977031022336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=19004)[0m 
[2m[36m(pid=19004)[0m W0716 20:31:23.683865 139977031022336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=19004)[0m 
[2m[36m(pid=19004)[0m W0716 20:31:23.683988 139977031022336 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=19004)[0m 
[2m[36m(pid=19004)[0m I0716 20:31:23.684061 139977031022336 train.py:24] calling setup
[2m[36m(pid=19004)[0m I0716 20:31:23.684326 139977031022336 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
[2m[36m(pid=18978)[0m W0716 20:31:23.683744 139697188763392 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.
[2m[36m(pid=18978)[0m 
[2m[36m(pid=18978)[0m W0716 20:31:23.683948 139697188763392 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:23: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.
[2m[36m(pid=18978)[0m 
[2m[36m(pid=18978)[0m W0716 20:31:23.684071 139697188763392 deprecation_wrapper.py:119] From /data/zwy/hack_pba_tensorflow/pba/train.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.
[2m[36m(pid=18978)[0m 
[2m[36m(pid=18978)[0m I0716 20:31:23.684144 139697188763392 train.py:24] calling setup
[2m[36m(pid=18978)[0m I0716 20:31:23.684440 139697188763392 data_utils.py:90] schedule policy trained on 10 epochs, parsing from: /data/zwy/hack_pba_tensorflow/schedules/hack.txt, multiplier: 1.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0.0/40 CPUs, 0.0/8 GPUs
Memory usage on this node: 3.9/270.4 GB
Result logdir: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train
Number of trials: 10 ({'ERROR': 10})
ERROR trials:
 - RayModel_0:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_0_2019-07-16_20-30-59spcrer22/error_2019-07-16_20-31-13.txt
 - RayModel_1:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_1_2019-07-16_20-30-59sm49bip3/error_2019-07-16_20-31-13.txt
 - RayModel_2:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_2_2019-07-16_20-30-59j22ogodp/error_2019-07-16_20-31-13.txt
 - RayModel_3:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_3_2019-07-16_20-30-59ygh4em_w/error_2019-07-16_20-31-13.txt
 - RayModel_4:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_4_2019-07-16_20-30-59kvo67rtj/error_2019-07-16_20-31-13.txt
 - RayModel_5:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_5_2019-07-16_20-30-59p_put295/error_2019-07-16_20-31-13.txt
 - RayModel_6:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_6_2019-07-16_20-30-594a_6lpw2/error_2019-07-16_20-31-13.txt
 - RayModel_7:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_7_2019-07-16_20-30-593tudowne/error_2019-07-16_20-31-13.txt
 - RayModel_8:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_8_2019-07-16_20-31-13spimzt23/error_2019-07-16_20-31-23.txt
 - RayModel_9:	ERROR, 4 failures: /data/zwy/hack_pba_tensorflow/results/resnet/resnet_train/RayModel_9_2019-07-16_20-31-13ssedk4vg/error_2019-07-16_20-31-23.txt

Traceback (most recent call last):
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 87, in <module>
    tf.app.run()
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/data/zwy/hack_pba_tensorflow/pba/train.py", line 82, in main
    run_experiments({args.name: train_spec})
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/tune.py", line 333, in run_experiments
    raise_on_failed_trial=raise_on_failed_trial)
  File "/data/anaconda3/envs/pba/lib/python3.6/site-packages/ray/tune/tune.py", line 273, in run
    raise TuneError("Trials did not complete", errored_trials)
ray.tune.error.TuneError: ('Trials did not complete', [RayModel_0, RayModel_1, RayModel_2, RayModel_3, RayModel_4, RayModel_5, RayModel_6, RayModel_7, RayModel_8, RayModel_9])
